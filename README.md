# Advance Computer Vision

| Submitted | Paper | Revised |
| --- | --- | --- |
|  26 Jan 2022 | [When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism](https://arxiv.org/abs/2201.10801) | |
| 24 Jan 2022 | [Patches Are All You Need?](https://arxiv.org/abs/2201.09792) | |
| 4 Jan 2022 | [PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture](https://arxiv.org/abs/2201.00978)| |
|  25 Jun 2021 | [PVTv2: Improved Baselines with Pyramid Vision Transformer](https://arxiv.org/abs/2106.13797) | 17 Jul 2021 |
|  28 Apr 2021 | [Twins: Revisiting the Design of Spatial Attention in Vision Transformers](https://arxiv.org/abs/2104.13840) | 30 Sep 2021 |
| 13 Apr 2021 | [Co-Scale Conv-Attentional Image Transformers](https://arxiv.org/abs/2104.06399) | 26 Aug 2021 |
| 12 Apr 2021 | [LocalViT: Bringing Locality to Vision Transformers](https://arxiv.org/abs/2104.05707) |  |
| 2 Apr 2021 | [LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference](https://arxiv.org/abs/2104.01136) | 6 May 2021 |
| 27 Mar 2021 | [CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification](https://arxiv.org/abs/2103.14899) | 22 Aug 2021 |
| 25 Mar 2021 | [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) | 17 Aug 2021 | 
| 27 Feb 2021 | [Transformer in Transformer](https://arxiv.org/abs/2103.00112) | 26 Oct 2021 |
| 24 Feb 2021) | [Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](https://arxiv.org/abs/2102.12122) | 11 Aug 2021 |
| 22 Feb 2021 | [Conditional Positional Encodings for Vision Transformers](https://arxiv.org/abs/2102.10882) |18 Mar 2021 |
| 28 Jan 2021 | [Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet](https://arxiv.org/abs/2101.11986) |30 Nov 2021 |
| 22 Oct 2020 | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) | 3 Jun 2021 |

## Resources:
* [Transformer-in-Vision-Researchpaper-Collections](https://github.com/DirtyHarryLYL/Transformer-in-Vision)
