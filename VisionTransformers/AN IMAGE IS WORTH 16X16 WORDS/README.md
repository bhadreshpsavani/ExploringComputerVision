# ViT:

interprets an **image as a sequence of patches** and process it by a standard Transformer encoder as used in NLP

![architecture](/VisionTransformers/AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS/vit_architecture.png)

## features:
* First Model to use standard transformer for computer vision

## Cons:
* requires pre-training on large datasets.
